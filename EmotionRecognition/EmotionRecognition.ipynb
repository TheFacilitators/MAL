{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e731acc",
   "metadata": {},
   "source": [
    "## Emotion recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7de29",
   "metadata": {},
   "source": [
    "Building emotion recognition model based on CREMA-D dataset and providing our own recordings to test its ability to generalise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(dataset_path):\n",
    "    # Loading the CREMA-D dataset\n",
    "    crema_directory_list = os.listdir(dataset_path)\n",
    "\n",
    "    file_emotion = []\n",
    "    file_path = []\n",
    "\n",
    "    for file in crema_directory_list:\n",
    "        # storing file paths\n",
    "        file_path.append(dataset_path + file)\n",
    "        # storing file emotions\n",
    "        part = file.split('_')\n",
    "        if part[2] == 'SAD':\n",
    "            file_emotion.append('sad')\n",
    "        elif part[2] == 'ANG':\n",
    "            file_emotion.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            file_emotion.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            file_emotion.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            file_emotion.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            file_emotion.append('neutral')\n",
    "        else:\n",
    "            file_emotion.append('Unknown')\n",
    "\n",
    "    # Create a DataFrame for emotion of files\n",
    "    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "    # Create a DataFrame for the path of files\n",
    "    path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "    crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "    # Convert the emotions to numerical format\n",
    "    label_encoder = LabelEncoder()\n",
    "    crema_df['Emotion_Label'] = label_encoder.fit_transform(crema_df['Emotions'])\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_df, test_df = train_test_split(crema_df, test_size=0.2, random_state=42)\n",
    "\n",
    "    return train_df, test_df, label_encoder\n",
    "\n",
    "\n",
    "# Set the path to the CREMA-D dataset\n",
    "crema_path = \"AudioWAV/\"\n",
    "\n",
    "# Load and process data\n",
    "train_df, test_df, label_encoder = load_and_process_data(crema_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13), axis=1)\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the feature extraction function to all audio files in the training set\n",
    "X_train = np.array([extract_features(file_path) for file_path in train_df['Path'].tolist()])\n",
    "y_train = train_df['Emotion_Label'].values\n",
    "\n",
    "# Apply the feature extraction function to all audio files in the testing set\n",
    "X_test = np.array([extract_features(file_path) for file_path in test_df['Path'].tolist()])\n",
    "y_test = test_df['Emotion_Label'].values\n",
    "\n",
    "# Build the neural network model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
