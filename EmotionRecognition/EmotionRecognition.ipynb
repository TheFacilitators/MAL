{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e731acc",
   "metadata": {},
   "source": [
    "## Emotion recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7de29",
   "metadata": {},
   "source": [
    "Building emotion recognition model based on CREMA-D dataset and providing our own recordings to test its ability to generalise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c10020",
   "metadata": {},
   "source": [
    "### Convert wav to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_npy(input_wav_path):\n",
    "    audio_data, _ = librosa.load(input_wav_path, sr=None)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "def save_all_to_single_npy(directory, output_npy_path, target_length=None):\n",
    "    X = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            input_wav_path = os.path.join(directory, filename)\n",
    "            loaded_data = wav_to_npy(input_wav_path)\n",
    "\n",
    "            # Ensure that the array has the target length by padding or truncating\n",
    "            if target_length is not None and len(loaded_data) != target_length:\n",
    "                if len(loaded_data) < target_length:\n",
    "                    # Pad with zeros if too short\n",
    "                    loaded_data = np.pad(loaded_data, (0, target_length - len(loaded_data)))\n",
    "                else:\n",
    "                    # Truncate if too long\n",
    "                    loaded_data = loaded_data[:target_length]\n",
    "\n",
    "            X.append(loaded_data)\n",
    "\n",
    "    # Save the entire list as a single NumPy file\n",
    "    np.save(output_npy_path, np.array(X))\n",
    "\n",
    "input_wav_directory = 'AudioWAV/'\n",
    "all_data_path = 'all_data.npy'\n",
    "target_length = 10000  \n",
    "\n",
    "save_all_to_single_npy(input_wav_directory, all_data_path, target_length=target_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d9b32",
   "metadata": {},
   "source": [
    "### Load CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load function courtesy of https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition\n",
    "\n",
    "def load_and_process_data(dataset_path):\n",
    "    crema_directory_list = os.listdir(dataset_path)\n",
    "\n",
    "    file_emotion = []\n",
    "    file_path = []\n",
    "\n",
    "    for file in crema_directory_list:\n",
    "        # storing file paths\n",
    "        file_path.append(dataset_path + file)\n",
    "        # storing file emotions\n",
    "        part = file.split('_')\n",
    "        if part[2] == 'SAD':\n",
    "            file_emotion.append('sad')\n",
    "        elif part[2] == 'ANG':\n",
    "            file_emotion.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            file_emotion.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            file_emotion.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            file_emotion.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            file_emotion.append('neutral')\n",
    "        else:\n",
    "            file_emotion.append('Unknown')\n",
    "\n",
    "    # Create a DataFrame for emotion of files\n",
    "    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "    # Create a DataFrame for the path of files\n",
    "    path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "    return path_df, emotion_df\n",
    "\n",
    "\n",
    "# Set the path to the CREMA-D dataset\n",
    "crema_path = \"AudioWAV/\"\n",
    "\n",
    "# Load and process data\n",
    "recordings_df, labels_df = load_and_process_data(crema_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c8ce9",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(emotion_labels):\n",
    "    unique_labels = np.unique(emotion_labels)\n",
    "    label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "    encoded_labels = [label_to_index[label] for label in emotion_labels]\n",
    "    return np.array(encoded_labels)\n",
    "\n",
    "# Load the single NumPy file\n",
    "X = np.load(all_data_path)\n",
    "\n",
    "# Encode emotion labels\n",
    "Y = encode_labels(labels_df['Emotions'])\n",
    "\n",
    "display(X.shape)\n",
    "display(Y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=69)\n",
    "\n",
    "# Assuming x_train and x_test are your input data\n",
    "# Convert to non-negative integers\n",
    "x_train_non_negative = (x_train + 1) * 5000 \n",
    "x_test_non_negative = (x_test + 1) * 5000\n",
    "\n",
    "# Convert to integers\n",
    "x_train_indices = x_train_non_negative.astype(int)\n",
    "x_test_indices = x_test_non_negative.astype(int)\n",
    "\n",
    "# Ensure values are within the vocabulary size (10000)\n",
    "x_train_indices = np.clip(x_train_indices, 0, 9999)\n",
    "x_test_indices = np.clip(x_test_indices, 0, 9999)\n",
    "\n",
    "# Assuming your data has shape (number_of_samples, sequence_length)\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=10000, output_dim=32, input_length=input_shape[0]))\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train_indices, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test_indices, y_test, verbose=1)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2b26c",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_indices)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "labels = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad']  \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
