{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc9be56",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b3b52",
   "metadata": {},
   "source": [
    "In this exercise we use the IMDb-dataset, which we will use to perform a sentiment analysis. The code below assumes that the data is placed in the same folder as this notebook. We see that the reviews are loaded as a pandas dataframe, and print the beginning of the first few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)\n",
    "Y = (labels=='positive').astype(np.int_)\n",
    "\n",
    "print(type(reviews))\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982b946",
   "metadata": {},
   "source": [
    "**(a)** Split the reviews and labels in test, train and validation sets. The train and validation sets will be used to train your model and tune hyperparameters, the test set will be saved for testing. Use the `CountVectorizer` from `sklearn.feature_extraction.text` to create a Bag-of-Words representation of the reviews. Only use the 10,000 most frequent words (use the `max_features`-parameter of `CountVectorizer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf07ee9",
   "metadata": {},
   "source": [
    "**(b)** Explore the representation of the reviews. How is a single word represented? How about a whole review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2638fce",
   "metadata": {},
   "source": [
    "**(c)** Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd327a6",
   "metadata": {},
   "source": [
    "**(d)** Test your sentiment-classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44ee62",
   "metadata": {},
   "source": [
    "**(e)** Use the classifier to classify a few sentences you write yourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(reviews, Y, test_size=0.3, random_state=43)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=43)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000, binary=True)\n",
    "\n",
    "# Transform the text data into a Bag-of-Words representation\n",
    "X_train_bow = vectorizer.fit_transform(X_train[0])\n",
    "X_val_bow = vectorizer.transform(X_val[0])\n",
    "X_test_bow = vectorizer.transform(X_test[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a654437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single word is represented as a binary vector with a 1 in the position corresponding to the word's index in the vocabulary \n",
    "# (1 if the word is present, 0 if not).\n",
    "\n",
    "# A whole review is represented as a binary vector with a 1 in the positions corresponding to the indices of words present in the review, \n",
    "# and 0 in the positions for words that are not in the review. Essentially, it's a sparse vector representing the presence of words in the review.\n",
    "\n",
    "\n",
    "#Example\n",
    "vocabulary = [\"Hello\", \"World\", \"Goodnight\", \"Moon\"]\n",
    "word_vector_for_moon = [0 ,0 ,0 ,1]\n",
    "sentance = \"Goodnight moon, goodnight moon, goodnight cow jumping over the moon\"\n",
    "sentence_vector = [0, 0, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(10000,)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_bow.toarray(), y_train, validation_data=(X_val_bow.toarray(), y_val), epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b550110",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_bow.toarray(), y_test)\n",
    "print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efedcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ \"I love this movie, it's awfully great!\",\n",
    "              \"This is the worst film I've ever seen.\", \n",
    "              \"My reaction to this movie was not neutral in a not unpleasant way\",\n",
    "              \"Not good, but great!\",\n",
    "              \"Hello, world.\", \n",
    "              \"Goodbye, world.\",\n",
    "              \"pokemon the movie was a terrible film . unlike the first one  this is not a good film at all . the graphics were decent but the story was flat and no real drama was built up in it . in the first one the interaction between the characters were decent . the subtraction of brock and addition of tracey was bad . tracey really doesn  t have much to say or do  and unlike brock offers no comic relief . the only good points is you get to see misty actually get jelous over ash  and her early brooding over being called his girlfriend was entertaining . overall this film isn  t worth renting and the short movie before didn  t do anything for me or my wife . and we do consider ourselves pokemon fans . oh well  maybe the next one will be better . cant ge t much worse  \"]\n",
    "\n",
    "# Vectorize the sentences using the same CountVectorizer\n",
    "sentences_bow = vectorizer.transform(sentences)\n",
    "\n",
    "# Predict sentiment for the sentences\n",
    "predictions = model.predict(sentences_bow.toarray())\n",
    "\n",
    "# Print the predictions\n",
    "for sentence, prediction in zip(sentences, predictions):\n",
    "    sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "    print(f\"Sentence: '{sentence}' - Predicted Sentiment: {sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
