{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278102b3",
   "metadata": {},
   "source": [
    "# Candidate Test 2022 Analysis\n",
    "\n",
    "This exercise focuses on the candidate tests from two television networks: DR and TV2. Data from both tests have been given on a scale of five responses (-2, -1, 0, 1, 2). Consider normalizing the data or performing similar scaling transformations as needed.\n",
    "\n",
    "---\n",
    "\n",
    "There are 6 datasets included in this exercise:\n",
    "\n",
    "- `alldata.xlsx`: Contains responses from both TV stations.\n",
    "- `drdata.xlsx`: Contains responses from DR.\n",
    "- `drq.xlsx`: Contains questions from DR.\n",
    "- `tv2data.xlsx`: Contains responses from TV2.\n",
    "- `tv2q.xlsx`: Contains questions from TV2.\n",
    "- `electeddata.xlsx`: Contains responses from both TV stations for candidates who were elected to the parliament. Note that 9 members are missing; 7 of them didn't take any of the tests. Additionally, some notable figures like Mette F. and Lars Løkke did not participate in any of the tests.\n",
    "\n",
    "---\n",
    "\n",
    "It's entirely up to you how you approach this data, but at a *minimum*, your analysis should include:\n",
    "\n",
    "- PCA or some other dimensionality reduction technique to plot responses in two dimensions, thereby visualizing the \"political landscape\". The colors of the plotted points should match the political party colors (see below).\n",
    "- An analysis/description of which questions are most crucial concerning their placement on the axes.\n",
    "- Average positions of parties concerning each question, preferably with accompanying plots of each (or selected) question.\n",
    "- Age of the candidates grouped by parties.\n",
    "- An overview of the most \"confident\" candidates, i.e., those with the highest proportion of \"strongly agree\" or \"strongly disagree\" responses.\n",
    "- Differences in responses between candidates, both inter-party and intra-party, along with an explanation of which parties have the most internal disagreements.\n",
    "- Classification models to predict candidates' party affiliations. Investigate if there are any candidates who seem to be in the \"wrong\" party based on their political landscape positions. You must use the following three algorithms: **Decision Tree, Random Forrest, and Gradient Boosted Tree**.\n",
    "- A clustering analysis where you attempt various cluster numbers, which would correspond to different parties. Discuss whether there is room for more clusters/parties or if a reduction is needed. Make sure you cover: **K-Means, Hierarchical clustering, and DBSCAN.**\n",
    "- An overview of the political landscape of the elected candidates, highlighting which members agree or disagree the most and which parties or party members have significant disagreements.\n",
    "- Feel free to explore further and remember that preprocessing, methodology, and evaluation metrics are not mentioned explicitly, but are implicitly assumed.\n",
    "\n",
    "---\n",
    "\n",
    "The following parties are represented:\n",
    "\n",
    "| Party letter | Party name | Party name (English) | Political position |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| A | Socialdemokratiet | Social Democrats | Centre-left |\n",
    "| V | Venstre | Danish Liberal Party | Centre-right |\n",
    "| M | Moderaterne | Moderates | Centre-right |\n",
    "| F | Socialistisk Folkeparti | Socialist People's Party | Left-wing |\n",
    "| Æ | Danmarksdemokraterne | Denmark Democrats | Right-wing |\n",
    "| I | Liberal Alliance | Liberal Alliance | Right-wing |\n",
    "| C | Konservative | Conservative People's Party | Right-wing |\n",
    "| Ø | Enhedslisten | Red-Green Alliance | Far-left |\n",
    "| B | Radikale Venstre | Social Liberal Party | Centre-left |\n",
    "| D | Nye Borgerlige | New Right | Far-right |\n",
    "| Z | Alternativet | The Alternative | Centre-left |\n",
    "| O | Dansk Folkeparti | Danish People's Party | Far-right |\n",
    "| G | Frie Grønne | Free Greens | Centre-left |\n",
    "| K | Kristendemokraterne | Christian Democrats | Centre-right |\n",
    "\n",
    "Below you can see the results and the colors chosen to represent the parties. Use these colors in your analysis above.\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "\n",
    "Others have undertaken similar analyses. You can draw inspiration from the following (use Google tranlsate if your Danish is rusty):\n",
    "\n",
    "- [Analysis of where individual candidates stand relative to each other and their parties](https://v2022.dumdata.dk/)\n",
    "- [Candidate Test 2022 – A deep dive into the data](https://kwedel.github.io/kandidattest2022/)\n",
    "- [The Political Landscape 2019](https://kwedel.github.io/kandidattest2019/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b111da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = pd.read_excel('alldata.xlsx')\n",
    "\n",
    "display(candidates_df.head(5))\n",
    "display(candidates_df.shape)\n",
    "\n",
    "#Might make sense to do some scaling, not sure. Probably will need to encode the candidate and polytical party names\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dee232",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_mapping = {\n",
    "    'Socialdemokratiet': '#C82518',  \n",
    "    'Venstre': '#01438E',  \n",
    "    'Moderaterne': '#B48CD2',  \n",
    "    'Socialistisk Folkeparti': '#eb94d1',  \n",
    "    'Danmarksdemokraterne': '#FFA500',  \n",
    "    'Liberal Alliance': '#3FB2BE', \n",
    "    'Det Konservative Folkeparti': '#00583C',  \n",
    "    'Enhedslisten': '#F7660D', \n",
    "    'Radikale Venstre': '#FF00FF',  \n",
    "    'Nye Borgerlige': '#00505B',  \n",
    "    'Alternativet': '#00FF00',  \n",
    "    'Dansk Folkeparti': '#FCD03B',  \n",
    "    'Frie Grønne, Danmarks Nye Venstrefløjsparti': '#d9b99b',  \n",
    "    'Kristendemokraterne': '#53619B',  \n",
    "    'Løsgænger': '#808080'  \n",
    "}\n",
    "\n",
    "colours = candidates_df['parti'].map(colour_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4b42c",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4455e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_candidates_df = candidates_df.copy()\n",
    "\n",
    "pca_candidates_df.drop(\"navn\", axis=1, inplace=True)\n",
    "pca_candidates_df.drop(\"storkreds\", axis=1, inplace=True)\n",
    "pca_candidates_df.drop(\"alder\", axis=1, inplace=True)\n",
    "\n",
    "# Numeric only df for PCA\n",
    "X = pca_candidates_df.select_dtypes(include=['number'])\n",
    "display(X.shape)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X)\n",
    "display(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the reduced data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=colours, marker='o', label='Candidates')\n",
    "plt.title('PCA of Candidate Responses')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabc1d1",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9308f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use reduced data from PCA \n",
    "#Use DBSCAN to cluster data\n",
    "\n",
    "eps_values = [0.5, 1.0, 1.5]  \n",
    "min_samples_values = [5, 10, 15]  \n",
    "\n",
    "best_silhouette_score = -1\n",
    "best_eps, best_min_samples = 0, 0\n",
    "best_labels = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(reduced_data)\n",
    "\n",
    "        if len(np.unique(labels)) > 1:  # Ensure more than one cluster is formed\n",
    "            silhouette_avg = silhouette_score(reduced_data, labels)\n",
    "            if silhouette_avg > best_silhouette_score:\n",
    "                best_silhouette_score = silhouette_avg\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "                best_labels = labels\n",
    "\n",
    "display(best_eps, best_min_samples )\n",
    "\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=best_labels, cmap='viridis')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27539d3",
   "metadata": {},
   "source": [
    "### Crucial question analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c585cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding out how much original features contribute to the two PCA. Printing out in descending order. Interestingly enough, the first PCA is pretty much solely determined by age\n",
    "\n",
    "# Get the PCA loadings\n",
    "loadings = pca.components_\n",
    "\n",
    "# Calculate the absolute values of loadings for each feature\n",
    "absolute_loadings = np.abs(loadings)\n",
    "\n",
    "# Create a DataFrame to show the absolute loadings\n",
    "loading_df = pd.DataFrame(absolute_loadings, columns=X.columns, index=['PC1', 'PC2'])\n",
    "\n",
    "# Sort the features based on their loadings in PC1\n",
    "sorted_features_pc1 = loading_df.loc['PC1'].sort_values(ascending=False)\n",
    "print(\"Features contributing the most to PC1:\")\n",
    "display(sorted_features_pc1)\n",
    "\n",
    "# Sort the features based on their loadings in PC2\n",
    "sorted_features_pc2 = loading_df.loc['PC2'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures contributing the most to PC2:\")\n",
    "display(sorted_features_pc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf0622",
   "metadata": {},
   "source": [
    "### Average position of parties concerning each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9034db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping features that are not relevant for assessing the mean for every party in relation to every question\n",
    "cleansed_candidates = candidates_df.copy()\n",
    "cleansed_candidates.drop(\"navn\", axis=1, inplace=True)\n",
    "cleansed_candidates.drop(\"storkreds\", axis=1, inplace=True)\n",
    "cleansed_candidates.drop(\"alder\", axis=1, inplace=True)\n",
    "\n",
    "display(cleansed_candidates.shape)\n",
    "display(candidates_df.shape)\n",
    "\n",
    "grouped_parties = cleansed_candidates.groupby(\"parti\")\n",
    "\n",
    "#Calculate the mean for every feature (question) within every group (party)\n",
    "mean_by_party = grouped_parties.mean()\n",
    "\n",
    "display(mean_by_party)\n",
    "\n",
    "# Plot for mean scores by party for each question. It is hard to see the mean for a specific question, but a general radical or mild tendency of parties can be seen\n",
    "mean_by_party.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Mean Scores by Party for Each Question')\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('Mean Score')\n",
    "plt.legend(title='Question', title_fontsize='12', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5102c",
   "metadata": {},
   "source": [
    "### Age of candidates grouped by parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29273c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar as previous one, but we want to keep the \"alder\" attribute\n",
    "\n",
    "cleansed_candidates = candidates_df.copy()\n",
    "cleansed_candidates.drop(\"navn\", axis=1, inplace=True)\n",
    "cleansed_candidates.drop(\"storkreds\", axis=1, inplace=True)\n",
    "\n",
    "grouped_parties = cleansed_candidates.groupby(\"parti\")\n",
    "\n",
    "means_by_party = grouped_parties.mean()\n",
    "\n",
    "# Select the \"question 530\" column from the mean_by_party DataFrame\n",
    "alder_means = means_by_party['alder']\n",
    "\n",
    "# Create a bar plot for mean scores of \"question 530\" by party\n",
    "alder_means.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Mean Age by Party')\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('Mean Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12051230",
   "metadata": {},
   "source": [
    "### Most confident candidates in terms of their answers to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510aad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total count of +2 and -2 answers for each candidate\n",
    "confidance_df = candidates_df.copy()\n",
    "\n",
    "confidance_df['+2_count'] = (candidates_df == 2).sum(axis=1)\n",
    "confidance_df['-2_count'] = (candidates_df == -2).sum(axis=1)\n",
    "\n",
    "confidance_df['ConfidentVotes'] = confidance_df['+2_count'] + confidance_df['-2_count']\n",
    "\n",
    "sorted_confidance_df = confidance_df[['ConfidentVotes', 'navn']].sort_values(by='ConfidentVotes', ascending=False)\n",
    "print(sorted_confidance_df)\n",
    "\n",
    "# Extract the top 10 rows\n",
    "top_10 = sorted_confidance_df.head(10)\n",
    "\n",
    "# Create a bar plot for the 'ConfidentVotes' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10['navn'], top_10['ConfidentVotes'], color='skyblue')\n",
    "plt.xlabel('Confident Votes')\n",
    "plt.ylabel('Candidate')\n",
    "plt.title('Top 10 Candidates with the Most Confident Votes')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6ae05",
   "metadata": {},
   "source": [
    "### Intra-party disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Intra-Party Differences\n",
    "intra_disagreements = candidates_df.copy()\n",
    "intra_disagreements.drop(\"navn\", axis=1, inplace=True)\n",
    "intra_disagreements.drop(\"storkreds\", axis=1, inplace=True)\n",
    "intra_disagreements.drop(\"alder\", axis=1, inplace=True)\n",
    "display(intra_disagreements.shape)\n",
    "#This calculates how much each candidate in a party disagrees in relation to other candidateso of the party (the disagreement is expressed as mean)\n",
    "intra_party_diff = intra_disagreements.groupby('parti').apply(lambda group: group.drop('parti', axis=1).diff(axis=1).mean(axis=1))\n",
    "\n",
    "sorted_intra_party_diff = intra_party_diff.groupby(level=0).apply(lambda x: x.sort_values(ascending=False))\n",
    "\n",
    "# Display the sorted DataFrame with scrollable output\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(sorted_intra_party_diff)\n",
    "\n",
    "#Perhaps not the most elegant representation, but it does display which candidates in each party are most disagreeing with the remaining ones in a descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043cf61",
   "metadata": {},
   "source": [
    "### Inter-party disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cab640",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_disagreements = candidates_df.copy()\n",
    "inter_disagreements.drop(\"navn\", axis=1, inplace=True)\n",
    "inter_disagreements.drop(\"storkreds\", axis=1, inplace=True)\n",
    "inter_disagreements.drop(\"alder\", axis=1, inplace=True)\n",
    "inter_disagreements.drop(\"parti\", axis=1, inplace=True)\n",
    "display(inter_disagreements.shape)\n",
    "\n",
    "inter_party_diff = inter_disagreements.diff(axis=1).mean(axis=1)\n",
    "\n",
    "sorted_inter_party_diff = inter_party_diff.sort_values(ascending=False)\n",
    "\n",
    "#Descending list of all candidates based on their disagreement mean in relation to all other candidates\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(sorted_inter_party_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627db03a",
   "metadata": {},
   "source": [
    "### Candidate affiliation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_df = candidates_df.copy()\n",
    "cleansed_df.drop(\"navn\", axis=1, inplace=True)\n",
    "cleansed_df.drop(\"storkreds\", axis=1, inplace=True)\n",
    "\n",
    "X = cleansed_df.drop('parti', axis=1)\n",
    "y = cleansed_df['parti']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Model Building\n",
    "# Train Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Gradient Boosted Tree model\n",
    "gbt_model = GradientBoostingClassifier()\n",
    "gbt_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "# Evaluate models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report\n",
    "\n",
    "dt_accuracy, dt_report = evaluate_model(dt_model, X_test, y_test)\n",
    "rf_accuracy, rf_report = evaluate_model(rf_model, X_test, y_test)\n",
    "gb_accuracy, gb_report = evaluate_model(gbt_model, X_test, y_test)\n",
    "\n",
    "# Print model evaluation results\n",
    "print(\"Decision Tree Accuracy:\\n\", dt_accuracy)\n",
    "print(\"Decision Tree Classification Report:\\n\", dt_report)\n",
    "print(\"Random Forest Accuracy:\\n\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
    "print(\"Gradient Boosted Tree Accuracy:\\n\", gb_accuracy)\n",
    "print(\"Gradient Boosted Tree Classification Report:\\n\", gb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca104c2",
   "metadata": {},
   "source": [
    "### Identifying switchovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ae844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predicted_party = rf_model.predict(X)\n",
    "\n",
    "# Calculate prediction probabilities for each party\n",
    "party_probabilities = rf_model.predict_proba(X)\n",
    "display(party_probabilities.shape)\n",
    "display(party_probabilities)\n",
    "\n",
    "# Set a threshold for switching parties (adjust as needed)\n",
    "# This should drastically affect how many candidates are considered switchovers, but for some reason it does not\n",
    "switch_threshold = 0.7\n",
    "\n",
    "# Identify candidates for switching parties\n",
    "switch_candidates = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if predicted_party[i] != y[i]:  # Check if predicted party is different from the actual party\n",
    "        new_party_prob = np.argmax(party_probabilities[i])\n",
    "        if new_party_prob > switch_threshold:\n",
    "            switch_candidates.append((i, predicted_party[i]))\n",
    "\n",
    "# 'switch_candidates' contains the index and predicted new party for candidates who may want to switch.\n",
    "\n",
    "# Print the results or further analyze them\n",
    "for index, new_party in switch_candidates:\n",
    "    print(f\"Candidate {candidates_df.loc[index, 'navn']} should consider switching to Party {new_party}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ddb01",
   "metadata": {},
   "source": [
    "### Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "inertia_values = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, 15)  # Try different numbers of clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(reduced_data)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "    if k > 1:  # Silhouette score is not defined for a single cluster\n",
    "        silhouette_scores.append(silhouette_score(reduced_data, kmeans.labels_))\n",
    "\n",
    "# Visualize K-Means results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, inertia_values, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('K-Means Elbow Method')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values[0:], silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('K-Means Silhouette Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#It seems that the sweet spot for the K-Means clustering is somewhere around 8 clusters as we want to maximize Silhouette Score and minimize Inertia\n",
    "\n",
    "# Hierarchical Clustering\n",
    "linked = linkage(reduced_data, method='ward')  # Try different linkage methods\n",
    "\n",
    "# Visualize dendrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
